{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Intro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Link: https://www.propublica.org/datastore/dataset/compas-recidivism-risk-score-data-and-analysis\n",
    "\n",
    "Class slides with basic info about dataset:\n",
    "https://docs.google.com/presentation/d/1RQZZpXmt1i-DyEEAZTFiBvrpuePFMJh69tXEWDPJIO8/edit#slide=id.g11f80bb4f73_0_115\n",
    "\n",
    "Dataset Github: https://github.com/propublica/compas-analysis\n",
    "\n",
    "A2 model github: https://github.com/mbilalzafar/fair-classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        2.1 Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from scipy.optimize import fmin_slsqp\n",
    "import sys\n",
    "sys.path.insert(0, \"/Users/xu/Desktop/5243 project4\")\n",
    "import utils as ut\n",
    "import loss_funcs as lf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        2.2 Data Cleaning and Wrangling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['id','sex','age','age_cat','race','decile_score','score_text','priors_count', \n",
    "'c_charge_degree',  'is_recid','r_charge_degree','is_violent_recid',\n",
    "'vr_charge_degree','v_decile_score', 'v_score_text',\n",
    "'two_year_recid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>id</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>score_text</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>length_of_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>10.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>4</td>\n",
       "      <td>1.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>41</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>14</td>\n",
       "      <td>6.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>39</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>2.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>21</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   two_year_recid  id     sex              race  age       age_cat  \\\n",
       "1               1   3    Male  African-American   34       25 - 45   \n",
       "2               1   4    Male  African-American   24  Less than 25   \n",
       "6               1   8    Male         Caucasian   41       25 - 45   \n",
       "8               0  10  Female         Caucasian   39       25 - 45   \n",
       "9               1  13    Male         Caucasian   21  Less than 25   \n",
       "\n",
       "   decile_score score_text c_charge_degree  is_recid  is_violent_recid  \\\n",
       "1             3        Low               F         1                 1   \n",
       "2             4        Low               F         1                 0   \n",
       "6             6     Medium               F         1                 0   \n",
       "8             1        Low               M         0                 0   \n",
       "9             3        Low               F         1                 1   \n",
       "\n",
       "   v_decile_score v_score_text  priors_count  length_of_stay  \n",
       "1               1          Low             0       10.041667  \n",
       "2               3          Low             4        1.083333  \n",
       "6               2          Low            14        6.291667  \n",
       "8               1          Low             0        2.916667  \n",
       "9               5       Medium             1        0.958333  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the raw dataset\n",
    "raw_data = pd.read_csv(\"/Users/xu/Desktop/5243 project4/compas-scores-two-years.csv\")\n",
    "# raw_data.head()\n",
    "\n",
    "# Create New Variable length_of_stay\n",
    "length_of_stay = pd.to_datetime(raw_data[\"c_jail_out\"]) - pd.to_datetime(raw_data[\"c_jail_in\"])\n",
    "length_of_stay_days = length_of_stay.astype('timedelta64[h]') / 24\n",
    "\n",
    "# Filtering the features we need\n",
    "filtered_df = raw_data.loc[\n",
    "    (raw_data[\"race\"].isin([\"African-American\", \"Caucasian\"])) &\n",
    "    (length_of_stay_days > 0)\n",
    "].assign(\n",
    "    length_of_stay=length_of_stay_days\n",
    ")[[\n",
    "    \"two_year_recid\", \"id\", \"sex\", \"race\", \"age\", \"age_cat\", \"decile_score\", \"score_text\", \"c_charge_degree\", \n",
    "    \"is_recid\", \"is_violent_recid\", \"v_decile_score\", \"v_score_text\", \"priors_count\", \"length_of_stay\"\n",
    "]]\n",
    "\n",
    "# Drop missing values\n",
    "filtered_df = filtered_df.dropna()\n",
    "\n",
    "# Display filtered data\n",
    "filtered_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length_of_stay does not contain negative numbers\n"
     ]
    }
   ],
   "source": [
    "if (filtered_df['length_of_stay'] < 0).any():\n",
    "    print(\"length_of_stay contains negative numbers\")\n",
    "else:\n",
    "    print(\"length_of_stay does not contain negative numbers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting some of the features to be binary or categorical\n",
    "filtered_df['sex'] = filtered_df['sex'].apply(lambda x: 1 if x == 'Male' else 0)\n",
    "filtered_df['race'] = filtered_df['race'].apply(lambda x: 1 if x == 'Caucasian' else 0)\n",
    "\n",
    "age_cat_map = {'Less than 25': 0, '25 - 45': 1, 'Greater than 45': 2}\n",
    "filtered_df['age_cat'] = filtered_df['age_cat'].apply(lambda x: age_cat_map[x])\n",
    "\n",
    "decile_score_map = {'Low': 0, 'Medium': 1, 'High': 2}\n",
    "filtered_df['score_text'] = filtered_df['score_text'].apply(lambda x: decile_score_map[x])\n",
    "\n",
    "filtered_df['c_charge_degree'] = filtered_df['c_charge_degree'].apply(lambda x: 1 if x == 'F' else 0)\n",
    "\n",
    "v_score_map = {'Low': 0, 'Medium': 1, 'High': 2}\n",
    "filtered_df['v_score_text'] = filtered_df['v_score_text'].apply(lambda x: v_score_map[x])\n",
    "\n",
    "# filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>score_text</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>length_of_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.738411</td>\n",
       "      <td>-0.187151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045203</td>\n",
       "      <td>-0.356541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.004240</td>\n",
       "      <td>-0.258059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.738411</td>\n",
       "      <td>-0.321875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.542508</td>\n",
       "      <td>-0.358905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   two_year_recid  sex  race  age_cat  c_charge_degree  v_score_text  \\\n",
       "0               1    1     0        1                1             0   \n",
       "1               1    1     0        0                1             0   \n",
       "2               1    1     1        1                1             0   \n",
       "3               0    0     1        1                0             0   \n",
       "4               1    1     1        0                1             1   \n",
       "\n",
       "   score_text  priors_count  length_of_stay  \n",
       "0           0     -0.738411       -0.187151  \n",
       "1           0      0.045203       -0.356541  \n",
       "2           1      2.004240       -0.258059  \n",
       "3           0     -0.738411       -0.321875  \n",
       "4           0     -0.542508       -0.358905  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Further features selection\n",
    "cleaned_data = filtered_df.loc[:, [\"two_year_recid\", \"sex\", \"race\", \"age_cat\", \"c_charge_degree\", \"v_score_text\",\n",
    "                                   \"score_text\", \"priors_count\", \"length_of_stay\"]]                       \n",
    "\n",
    "# Normalize priors_count and length_of_stay\n",
    "cleaned_data[\"priors_count\"] = (cleaned_data[\"priors_count\"] - cleaned_data[\"priors_count\"].mean())/cleaned_data[\"priors_count\"].std()\n",
    "cleaned_data[\"length_of_stay\"] = (cleaned_data[\"length_of_stay\"] - cleaned_data[\"length_of_stay\"].mean())/cleaned_data[\"length_of_stay\"].std()\n",
    "\n",
    "cleaned_data = cleaned_data.reset_index(drop=True)\n",
    "cleaned_data.head()\n",
    "\n",
    "# len(cleaned_data)       5699rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        2.3 Splitting Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (3989, 9)\n",
      "Validation set shape: (855, 9)\n",
      "Testing set shape: (855, 9)\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.7  # 70% for training\n",
    "val_ratio = 0.15  # 15% for validation\n",
    "test_ratio = 0.15  # 15% for testing\n",
    "\n",
    "# Spliting the dataframe into train, val, and test with roughly 5:1:1\n",
    "train_val, test = train_test_split(cleaned_data, test_size=test_ratio, random_state=110)\n",
    "train, val = train_test_split(train_val, test_size=val_ratio/(train_ratio+val_ratio), random_state=110)\n",
    "\n",
    "# print the shapes of the resulting dataframes\n",
    "print(f\"Training set shape: {train.shape}\")\n",
    "print(f\"Validation set shape: {val.shape}\")\n",
    "print(f\"Testing set shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"two_year_recid\"\n",
    "sensitive_feature = \"race\"\n",
    "features = list(cleaned_data.columns)\n",
    "\n",
    "X_train = train.drop(label, axis=1)\n",
    "Y_train = train[label].to_numpy()\n",
    "\n",
    "X_val = val.drop(label, axis=1)\n",
    "Y_val = val[label].to_numpy()\n",
    "\n",
    "X_test = test.drop(label, axis=1)\n",
    "Y_test = test[label].to_numpy()\n",
    "\n",
    "race_train = train[sensitive_feature]\n",
    "race_val = val[sensitive_feature]\n",
    "race_test = test[sensitive_feature]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Functions defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration\n",
    "# Computes the calibration difference between Caucasians and African-Americans groups in the predicted outcomes.\n",
    "def calibrate_difference(sensitive_features, y_pred, y_true):\n",
    "    caucasians_index = np.where(sensitive_features == 1)[0]\n",
    "    aa_index = np.where(sensitive_features == 0)[0]\n",
    "    \n",
    "    y_pred_caucasians = y_pred[caucasians_index]\n",
    "    y_true_caucasians = y_true[caucasians_index]\n",
    "    \n",
    "    y_pred_aa = y_pred[aa_index]\n",
    "    y_true_aa = y_true[aa_index]\n",
    "    accuracy_caucasians = sum(y_pred_caucasians == y_true_caucasians) / len(y_true_caucasians)\n",
    "    accuracy_aa = sum(y_pred_aa == y_true_aa) / len(y_true_aa)\n",
    "    calib_diff = abs(accuracy_caucasians - accuracy_aa)\n",
    "    return calib_diff\n",
    "\n",
    "\n",
    "# Parity_ratio\n",
    "def parity_ratio(y_pred, sensitive_features):\n",
    "    assert len(y_pred) == len(sensitive_features), \"Input arrays must have the same length\"\n",
    "    \n",
    "    y_pred = np.array(y_pred)\n",
    "    sensitive_features = np.array(sensitive_features)\n",
    "\n",
    "    # Separate the data into two groups based on the sensitive feature\n",
    "    y_pred_caucasians = y_pred[sensitive_features == 1]\n",
    "    y_pred_aa = y_pred[sensitive_features == 0]\n",
    "\n",
    "    # Calculate the probabilities of receiving a positive prediction for both groups\n",
    "    prob_aa = np.mean(y_pred_aa == 1)\n",
    "    prob_caucasians = np.mean(y_pred_caucasians == 1)\n",
    "\n",
    "    # Calculate the parity ratio\n",
    "    parity_ratio = prob_aa / prob_caucasians\n",
    "\n",
    "    return parity_ratio\n",
    "\n",
    "\n",
    "\n",
    "def p_rule(sensitive_features, y_pred):\n",
    "    caucasians_index = np.where(sensitive_features == 1)[0]\n",
    "    aa_index = np.where(sensitive_features == 0)[0]\n",
    "    caucasians_pred = np.where(y_pred[caucasians_index] == 1)\n",
    "    aa_pred = np.where(y_pred[aa_index] == 1)\n",
    "    caucasians_percent = caucasians_pred[0].shape[0]/caucasians_index.shape[0]\n",
    "    aa_percent = aa_pred[0].shape[0]/aa_index.shape[0]\n",
    "    ratio = min(caucasians_percent/aa_percent, aa_percent/caucasians_percent)\n",
    "    \n",
    "    return ratio, caucasians_percent, aa_percent\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Baseline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation set: 0.672514619883041\n",
      "Test accuracy: 0.6573\n"
     ]
    }
   ],
   "source": [
    "# Fit a logistic regression classifier\n",
    "lr_base = LogisticRegression(random_state=110)\n",
    "lr_base.fit(X_train, Y_train)\n",
    "\n",
    "# On validation set\n",
    "accuracy_lr_base_val = lr_base.score(X_val, Y_val)\n",
    "print(f\"Accuracy on the validation set: {accuracy_lr_base_val}\")\n",
    "\n",
    "# Testing \n",
    "accuracy_lr_base_test = lr_base.score(X_test, Y_test)\n",
    "print(f\"Test accuracy: {accuracy_lr_base_test:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        3.2 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation set: 0.6678362573099416\n",
      "Test accuracy: 0.6585\n"
     ]
    }
   ],
   "source": [
    "# Fit an SVM classifier\n",
    "svm_base = SVC(random_state=110)\n",
    "svm_base.fit(X_train, Y_train)\n",
    "\n",
    "# On validation\n",
    "accuracy_svm_base_val = svm_base.score(X_val, Y_val)\n",
    "print(f\"Accuracy on the validation set: {accuracy_svm_base_val}\")\n",
    "\n",
    "# Testing\n",
    "accuracy_svm_base_test = svm_base.score(X_test, Y_test)\n",
    "print(f\"Test accuracy: {accuracy_svm_base_test:.4f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        3.3 Summary of Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methods</th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Calibration(%)</th>\n",
       "      <th>parity_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>Train</td>\n",
       "      <td>67.251462</td>\n",
       "      <td>2.555860</td>\n",
       "      <td>0.495499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>Test</td>\n",
       "      <td>65.730994</td>\n",
       "      <td>0.393226</td>\n",
       "      <td>0.544211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Train</td>\n",
       "      <td>66.783626</td>\n",
       "      <td>3.488891</td>\n",
       "      <td>0.579274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Test</td>\n",
       "      <td>65.847953</td>\n",
       "      <td>2.654994</td>\n",
       "      <td>0.634721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Methods    Set  Accuracy (%)  Calibration(%)  parity_ratio\n",
       "0      LR  Train     67.251462        2.555860      0.495499\n",
       "1      LR   Test     65.730994        0.393226      0.544211\n",
       "2     SVM  Train     66.783626        3.488891      0.579274\n",
       "3     SVM   Test     65.847953        2.654994      0.634721"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_baseline = {\"Methods\": [\"LR\", \"LR\", \"SVM\", \"SVM\"], \n",
    "              \"Set\": [\"Train\", \"Test\", \"Train\", \"Test\"],\n",
    "              \"Accuracy (%)\": [accuracy_lr_base_val*100, accuracy_lr_base_test*100, accuracy_svm_base_val*100, accuracy_svm_base_test*100],\n",
    "              \"Calibration(%)\": [calibrate_difference(race_train, lr_base.predict(X_train), Y_train)*100,\n",
    "                                 calibrate_difference(race_test, lr_base.predict(X_test), Y_test)*100,\n",
    "                                 calibrate_difference(race_train, svm_base.predict(X_train), Y_train)*100,\n",
    "                                 calibrate_difference(race_test, svm_base.predict(X_test), Y_test)*100],\n",
    "              \"parity_ratio\": [p_rule(race_train, lr_base.predict(X_train))[0],\n",
    "                                 p_rule(race_test, lr_base.predict(X_test))[0],\n",
    "                                 p_rule(race_train, svm_base.predict(X_train))[0],\n",
    "                                 p_rule(race_test, svm_base.predict(X_test))[0]]}\n",
    "pd.DataFrame(summary_baseline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Optimization with Fairness Constraints (Paper A2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        4.1 CLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_control = {'race': race_train}\n",
    "loss_function = lf._logistic_loss\n",
    "\n",
    "apply_fairness_constraints = 1 # set this flag to 1 since we want to optimize accuracy subject to fairness constraints\n",
    "apply_accuracy_constraint = 0\n",
    "\n",
    "sep_constraint = 0\n",
    "gamma = None\n",
    "sensitive_attrs = ['race']\n",
    "sensitive_attrs_to_cov_thresh = {'race': 0}\n",
    "\n",
    "\n",
    "# Train model\n",
    "np.random.seed(100)\n",
    "w = ut.train_model(X_train,\n",
    "                   Y_train,\n",
    "                   x_control,\n",
    "                   loss_function,\n",
    "                   apply_fairness_constraints,\n",
    "                   apply_accuracy_constraint,\n",
    "                   sep_constraint,\n",
    "                   sensitive_attrs,\n",
    "                   sensitive_attrs_to_cov_thresh,\n",
    "                   gamma)\n",
    "\n",
    "\n",
    "# Fit coefficients/weights into logistic regression in sklearn\n",
    "CLR = LogisticRegression()\n",
    "CLR.coef_= w.reshape((1,-1))\n",
    "CLR.intercept_ = 0\n",
    "CLR.classes_ = np.array([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation set: 0.48771929824561405\n",
      "Test accuracy: 0.4982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xu/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:402: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/xu/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:402: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# On validation set\n",
    "accuracy_CLR_val = CLR.score(X_val, Y_val)\n",
    "print(f\"Accuracy on the validation set: {accuracy_CLR_val}\")\n",
    "\n",
    "# Testing \n",
    "accuracy_CLR_test = CLR.score(X_test, Y_test)\n",
    "print(f\"Test accuracy: {accuracy_CLR_test:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        4.2 CSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_CLR = {\"Classifier\": [\"C-LR\", \"C-LR\"],\n",
    "#                \"Set\": [\"Train\", \"Test\"],\n",
    "#                \"P-rule (%)\": [p_rule(race_train, m.predict(X_train))[0]*100, p_rule(race_test, m.predict(X_test))[0]*100],\n",
    "#                \"Accuracy (%)\": [m.score(X_train, Y_train)*100, m.score(X_test, Y_test)*100], \n",
    "#                \"Protected (%)\": [p_rule(race_train, m.predict(X_train))[1]*100, p_rule(race_test, m.predict(X_test))[1]*100],\n",
    "#                \"Not protected (%)\": [p_rule(race_train, m.predict(X_train))[2]*100, p_rule(race_test, m.predict(X_test))[2]*100],\n",
    "#                \"Calibration (%)\": [calibrate_difference(race_train, m.predict(X_train), Y_train)*100, calibrate_difference(race_test, m.predict(X_test), Y_test)*100]\n",
    "#              }\n",
    "# pd.DataFrame(result_CLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xu/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:402: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/xu/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:402: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/xu/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:402: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/xu/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:402: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methods</th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Calibration(%)</th>\n",
       "      <th>parity_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLR</td>\n",
       "      <td>Train</td>\n",
       "      <td>48.771930</td>\n",
       "      <td>13.514380</td>\n",
       "      <td>0.999584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLR</td>\n",
       "      <td>Test</td>\n",
       "      <td>49.824561</td>\n",
       "      <td>8.791619</td>\n",
       "      <td>0.998936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CSVM</td>\n",
       "      <td>Train</td>\n",
       "      <td>66.783626</td>\n",
       "      <td>3.488891</td>\n",
       "      <td>0.579274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Test</td>\n",
       "      <td>65.847953</td>\n",
       "      <td>2.654994</td>\n",
       "      <td>0.634721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Methods    Set  Accuracy (%)  Calibration(%)  parity_ratio\n",
       "0     CLR  Train     48.771930       13.514380      0.999584\n",
       "1     CLR   Test     49.824561        8.791619      0.998936\n",
       "2    CSVM  Train     66.783626        3.488891      0.579274\n",
       "3     SVM   Test     65.847953        2.654994      0.634721"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_A2 = {\"Methods\": [\"CLR\", \"CLR\", \"CSVM\", \"SVM\"], \n",
    "              \"Set\": [\"Train\", \"Test\", \"Train\", \"Test\"],\n",
    "              \"Accuracy (%)\": [accuracy_CLR_val*100, accuracy_CLR_test*100, accuracy_svm_base_val*100, accuracy_svm_base_test*100],\n",
    "              \"Calibration(%)\": [calibrate_difference(race_train, CLR.predict(X_train), Y_train)*100,\n",
    "                                 calibrate_difference(race_test, CLR.predict(X_test), Y_test)*100,\n",
    "                                 calibrate_difference(race_train, svm_base.predict(X_train), Y_train)*100,\n",
    "                                 calibrate_difference(race_test, svm_base.predict(X_test), Y_test)*100],\n",
    "              \"parity_ratio\": [p_rule(race_train, CLR.predict(X_train))[0],\n",
    "                                 p_rule(race_test, CLR.predict(X_test))[0],\n",
    "                                 p_rule(race_train, svm_base.predict(X_train))[0],\n",
    "                                 p_rule(race_test, svm_base.predict(X_test))[0]]}\n",
    "\n",
    "pd.DataFrame(summary_A2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Local Massaging & Local Preferential Sampling (Paper A6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        5.1 Local Massaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df is the dataframe with all columns to be partitioned\n",
    "#e is the name of explainatory varaible\n",
    "def PARTITION(df, e):\n",
    "    groups = []\n",
    "    uniques = np.unique(df[e])\n",
    "    for u in uniques:\n",
    "        groups.append(df[df[e]==u])\n",
    "    return groups\n",
    "    \n",
    "#part is the dataframe with all columns with same value for the explainatory variable\n",
    "#si is the current sensitive parameter value\n",
    "def DELTA(df, part, si):\n",
    "    isRace = part['race']==si\n",
    "    Gi = sum(isRace)\n",
    "    n = len(df)\n",
    "    \n",
    "    num = sum(part[isRace]['two_year_recid']==1)/n\n",
    "    denom = len(part[isRace])/n\n",
    "    P = num/denom\n",
    "    \n",
    "    isNotRace = part['race']!=si\n",
    "    num = sum(part[isNotRace]['two_year_recid']==1)/n\n",
    "    denom = len(part[isNotRace])/n\n",
    "\n",
    "    P_star = 0.5*(P + num/denom) #explainable difference\n",
    "    return np.floor(Gi*abs(P-P_star)).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Local Massaging algorithm\n",
    "LM_labels = []\n",
    "for part in PARTITION(train, 'c_charge_degree'):\n",
    "    #train model\n",
    "    X_part = part.drop('two_year_recid', axis=1)\n",
    "    y_part = part['two_year_recid']\n",
    "    log_model = LogisticRegression(random_state=110)\n",
    "    model=log_model.fit(X_part, y_part)\n",
    "    \n",
    "    #predict labels from model\n",
    "    part1 = part[part['race']==1]\n",
    "    part1.reset_index(drop=True, inplace=True)\n",
    "    delta1 = DELTA(train, part, 1)\n",
    "    X_part1 = part1.drop('two_year_recid', axis=1)\n",
    "    y_part1 = part1['two_year_recid']\n",
    "    rank = pd.DataFrame(model.decision_function(X_part1), columns = ['rank'])\n",
    "    comb1 = pd.concat([part1, rank], axis=1)\n",
    "    \n",
    "    part0 = part[part['race']==0]\n",
    "    part0.reset_index(drop=True, inplace=True)\n",
    "    delta0 = DELTA(train, part, 0)\n",
    "    X_part0 = part0.drop('two_year_recid', axis=1)\n",
    "    y_part0 = part0['two_year_recid']\n",
    "    rank = pd.DataFrame(model.decision_function(X_part0), columns = ['rank'])\n",
    "    comb0 = pd.concat([part0, rank], axis=1)\n",
    "\n",
    "    #for C, relabel closest delta datapoints from C to AA\n",
    "    comb1 = comb1.sort_values(['rank'])\n",
    "    comb1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    t = sum(comb1['rank']>0)\n",
    "    l = len(comb1)\n",
    "    \n",
    "    fix1 = np.full(l-t, False)\n",
    "    relabel = np.full(delta1, True)\n",
    "    fix2 = np.full(t-delta1, False)\n",
    "    comb1.loc[np.concatenate([fix1, relabel, fix2]), 'two_year_recid'] = 0\n",
    "    LM_labels.append(comb1)\n",
    "    \n",
    "    #for AA, relabel closest delta datapoints from AA to C\n",
    "    comb0 = comb0.sort_values(['rank'])\n",
    "    comb0.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    t = sum(comb0['rank']<0)\n",
    "    l = len(comb0)\n",
    "    \n",
    "    fix1 = np.full(t-delta0, False)\n",
    "    relabel = np.full(delta0, True)\n",
    "    fix2 = np.full(l-t, False)\n",
    "    comb0.loc[np.concatenate([fix1, relabel, fix2]), 'two_year_recid'] = 1\n",
    "    LM_labels.append(comb0)\n",
    "    \n",
    "loc_mass = pd.concat(LM_parts, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6736842105263158"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=[\"sex\", \"race\", \"age_cat\", \"c_charge_degree\", \"v_score_text\",\n",
    "                                   \"score_text\", \"priors_count\", \"length_of_stay\"]\n",
    "X_train = loc_mass[features]\n",
    "y_train = loc_mass['two_year_recid']\n",
    "log_model = LogisticRegression(random_state=110)\n",
    "classifier=log_model.fit(X_train, y_train)\n",
    "classifier.score(X_val, Y_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        5.2 Local Preferential Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Local Preferential Sampling\n",
    "LPS_labels = []\n",
    "partition = PARTITION(train, 'c_charge_degree')\n",
    "for part in partition:\n",
    "    #train model\n",
    "    X_part = part.drop(\"two_year_recid\", axis=1)\n",
    "    y_part = part[\"two_year_recid\"]\n",
    "    log_model = LogisticRegression(random_state=110)\n",
    "    model = log_model.fit(X_part, y_part)\n",
    "    \n",
    "    #predict labels from model\n",
    "    part1 = part[part[\"race\"]==1]\n",
    "    part1.reset_index(drop=True, inplace=True)\n",
    "    delta1 = DELTA(train, part, 1)//2\n",
    "    X_part1 = part1.drop(\"two_year_recid\", axis=1)\n",
    "    y_part1 = part1[\"two_year_recid\"]\n",
    "    rank = pd.DataFrame(model.decision_function(X_part1), columns = ['rank'])\n",
    "    comb1 = pd.concat([part1, rank], axis=1)\n",
    "    \n",
    "    part0 = part[part[\"race\"]==0]\n",
    "    part0.reset_index(drop=True, inplace=True)\n",
    "    delta0 = DELTA(train, part, 0)//2\n",
    "    X_part0 = part0.drop(\"two_year_recid\", axis=1)\n",
    "    y_part0 = part0[\"two_year_recid\"]\n",
    "    rank = pd.DataFrame(model.decision_function(X_part0), columns = ['rank'])\n",
    "    comb0 = pd.concat([part0, rank], axis=1)\n",
    "\n",
    "    #for C, replace closest delta/2 data with duplicates from same number of AA \n",
    "    comb1 = comb1.sort_values([\"rank\"])\n",
    "    comb1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    t = sum(comb1[\"rank\"]>0)\n",
    "    l = len(comb1)\n",
    "    \n",
    "    keep1 = np.full(l-t, False)\n",
    "    replace = np.full(delta1, True)\n",
    "    keep2 = np.full(t-delta1, False)\n",
    "    toKeep = np.invert(np.concatenate([keep1, replace, keep2]))\n",
    "    dup1 = np.full(l-t-delta1, False)\n",
    "    dup2 = np.full(t, False)\n",
    "    toDup = np.concatenate([dup1, replace, dup2])\n",
    "    duplicates = comb1[toDup]\n",
    "    comb1 = comb1[toKeep]\n",
    "    comb1 = pd.concat([comb1,duplicates], axis=0)\n",
    "    LPS_labels.append(comb1)\n",
    "    \n",
    "    #for AA, replace closest delta/2 data with duplicates from same number of C \n",
    "    comb0 = comb0.sort_values(['rank'])\n",
    "    comb0.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    t = sum(comb0['rank']<0)\n",
    "    l = len(comb0)\n",
    "    \n",
    "    keep1 = np.full(t-delta0, False)\n",
    "    replace = np.full(delta0, True)\n",
    "    keep2 = np.full(l-t, False)\n",
    "    toKeep = np.invert(np.concatenate([keep1, replace, keep2]))\n",
    "    dup1 = np.full(t, False)\n",
    "    dup2 = np.full(l-t-delta0, False)\n",
    "    toDup = np.concatenate([dup1, replace, dup2])\n",
    "    duplicates = comb0[toDup]\n",
    "    comb0 = comb0[toKeep]\n",
    "    comb0 = pd.concat([comb0,duplicates], axis=0)\n",
    "    LPS_labels.append(comb0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
