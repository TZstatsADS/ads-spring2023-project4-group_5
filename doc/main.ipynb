{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4ï¼šMachine Learning Fairness Algorithms Evaluation\n",
    "# 1. Intro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links: <br>\n",
    "Dataset: https://www.propublica.org/datastore/dataset/compas-recidivism-risk-score-data-and-analysis <br>\n",
    "Class slides with basic info about dataset: https://docs.google.com/presentation/d/1RQZZpXmt1i-DyEEAZTFiBvrpuePFMJh69tXEWDPJIO8/edit#slide=id.g11f80bb4f73_0_115 <br>\n",
    "Dataset Github: https://github.com/propublica/compas-analysis <br>\n",
    "A2 model github: https://github.com/mbilalzafar/fair-classification <br>\n",
    "\n",
    "Papers: <br>\n",
    "Maximizing accuracy under fairness constraints (C-SVM and C-LR) <br>\n",
    "Handling Conditional Discrimination (LM and LPS) <br>\n",
    "\n",
    "Team Members:\n",
    "1. Arceneaux, Luke lpa2114@columbia.edu\n",
    "2. Ren, Xiaoxue xr2159@columbia.edu\n",
    "3. Wei, Jiahao jw4312@columbia.edu\n",
    "4. Xia, Weijie wx2281@columbia.edu\n",
    "5. Xu, Mingze mx2269@columbia.edu\n",
    "6. Zhu, Yiming yz4336@columbia.edu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        2.1 Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from scipy.optimize import fmin_slsqp\n",
    "import sys\n",
    "sys.path.insert(0, '../lib/')\n",
    "import utils as ut\n",
    "import loss_funcs as lf\n",
    "import csvm as csvm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        2.2 Data Cleaning and Wrangling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directly observing the data, we see that there are 52 features. Some of them are useful, while some are not. <br>\n",
    "As a result, we decided to extract the features that are useful in this project. <br>\n",
    "An initial feature selection is about these: ['id','sex','age','age_cat','race','decile_score','score_text','priors_count', <br>\n",
    "'c_charge_degree',  'is_recid','r_charge_degree','is_violent_recid', 'vr_charge_degree','v_decile_score', 'v_score_text','two_year_recid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>id</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>score_text</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>length_of_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>10.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>4</td>\n",
       "      <td>1.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>41</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>14</td>\n",
       "      <td>6.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>39</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>2.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>21</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   two_year_recid  id     sex              race  age       age_cat  \\\n",
       "1               1   3    Male  African-American   34       25 - 45   \n",
       "2               1   4    Male  African-American   24  Less than 25   \n",
       "6               1   8    Male         Caucasian   41       25 - 45   \n",
       "8               0  10  Female         Caucasian   39       25 - 45   \n",
       "9               1  13    Male         Caucasian   21  Less than 25   \n",
       "\n",
       "   decile_score score_text c_charge_degree  is_recid  is_violent_recid  \\\n",
       "1             3        Low               F         1                 1   \n",
       "2             4        Low               F         1                 0   \n",
       "6             6     Medium               F         1                 0   \n",
       "8             1        Low               M         0                 0   \n",
       "9             3        Low               F         1                 1   \n",
       "\n",
       "   v_decile_score v_score_text  priors_count  length_of_stay  \n",
       "1               1          Low             0       10.041667  \n",
       "2               3          Low             4        1.083333  \n",
       "6               2          Low            14        6.291667  \n",
       "8               1          Low             0        2.916667  \n",
       "9               5       Medium             1        0.958333  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the raw dataset\n",
    "raw_data = pd.read_csv(\"/Users/xu/Desktop/5243 project4/compas-scores-two-years.csv\")\n",
    "# raw_data.head()\n",
    "\n",
    "# Create New Variable length_of_stay\n",
    "length_of_stay = pd.to_datetime(raw_data[\"c_jail_out\"]) - pd.to_datetime(raw_data[\"c_jail_in\"])\n",
    "length_of_stay_days = length_of_stay.astype('timedelta64[h]') / 24\n",
    "\n",
    "# Filtering the features we need\n",
    "filtered_df = raw_data.loc[\n",
    "    (raw_data[\"race\"].isin([\"African-American\", \"Caucasian\"])) &\n",
    "    (length_of_stay_days > 0)\n",
    "].assign(\n",
    "    length_of_stay=length_of_stay_days\n",
    ")[[\n",
    "    \"two_year_recid\", \"id\", \"sex\", \"race\", \"age\", \"age_cat\", \"decile_score\", \"score_text\", \"c_charge_degree\", \n",
    "    \"is_recid\", \"is_violent_recid\", \"v_decile_score\", \"v_score_text\", \"priors_count\", \"length_of_stay\"\n",
    "]]\n",
    "\n",
    "# Drop missing values\n",
    "filtered_df = filtered_df.dropna()\n",
    "\n",
    "# Display filtered data\n",
    "filtered_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length_of_stay does not contain negative numbers\n"
     ]
    }
   ],
   "source": [
    "# Check if any of the length_of_stay is negative, which is unreasonable.\n",
    "if (filtered_df['length_of_stay'] < 0).any():\n",
    "    print(\"length_of_stay contains negative numbers\")\n",
    "else:\n",
    "    print(\"length_of_stay does not contain negative numbers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting some of the features to be binary or categorical\n",
    "filtered_df['sex'] = filtered_df['sex'].apply(lambda x: 1 if x == 'Male' else 0)\n",
    "filtered_df['race'] = filtered_df['race'].apply(lambda x: 1 if x == 'Caucasian' else 0)\n",
    "\n",
    "age_cat_map = {'Less than 25': 0, '25 - 45': 1, 'Greater than 45': 2}\n",
    "filtered_df['age_cat'] = filtered_df['age_cat'].apply(lambda x: age_cat_map[x])\n",
    "\n",
    "decile_score_map = {'Low': 0, 'Medium': 1, 'High': 2}\n",
    "filtered_df['score_text'] = filtered_df['score_text'].apply(lambda x: decile_score_map[x])\n",
    "\n",
    "filtered_df['c_charge_degree'] = filtered_df['c_charge_degree'].apply(lambda x: 1 if x == 'F' else 0)\n",
    "\n",
    "v_score_map = {'Low': 0, 'Medium': 1, 'High': 2}\n",
    "filtered_df['v_score_text'] = filtered_df['v_score_text'].apply(lambda x: v_score_map[x])\n",
    "\n",
    "# filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>score_text</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>length_of_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.738411</td>\n",
       "      <td>-0.187151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045203</td>\n",
       "      <td>-0.356541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.004240</td>\n",
       "      <td>-0.258059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.738411</td>\n",
       "      <td>-0.321875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.542508</td>\n",
       "      <td>-0.358905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   two_year_recid  sex  race  age_cat  c_charge_degree  v_score_text  \\\n",
       "0               1    1     0        1                1             0   \n",
       "1               1    1     0        0                1             0   \n",
       "2               1    1     1        1                1             0   \n",
       "3               0    0     1        1                0             0   \n",
       "4               1    1     1        0                1             1   \n",
       "\n",
       "   score_text  priors_count  length_of_stay  \n",
       "0           0     -0.738411       -0.187151  \n",
       "1           0      0.045203       -0.356541  \n",
       "2           1      2.004240       -0.258059  \n",
       "3           0     -0.738411       -0.321875  \n",
       "4           0     -0.542508       -0.358905  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Further features selection\n",
    "cleaned_data = filtered_df.loc[:, [\"two_year_recid\", \"sex\", \"race\", \"age_cat\", \"c_charge_degree\", \"v_score_text\",\n",
    "                                   \"score_text\", \"priors_count\", \"length_of_stay\"]]                       \n",
    "\n",
    "# Normalize priors_count and length_of_stay\n",
    "cleaned_data[\"priors_count\"] = (cleaned_data[\"priors_count\"] - cleaned_data[\"priors_count\"].mean())/cleaned_data[\"priors_count\"].std()\n",
    "cleaned_data[\"length_of_stay\"] = (cleaned_data[\"length_of_stay\"] - cleaned_data[\"length_of_stay\"].mean())/cleaned_data[\"length_of_stay\"].std()\n",
    "\n",
    "# cleaned_data is the final cleaned dataframe that we end up with\n",
    "cleaned_data = cleaned_data.reset_index(drop=True)\n",
    "\n",
    "# Display a few lines of the cleaned data\n",
    "cleaned_data.head()\n",
    "\n",
    "# len(cleaned_data)       5699rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        2.3 Splitting Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (3989, 9)\n",
      "Validation set shape: (855, 9)\n",
      "Testing set shape: (855, 9)\n"
     ]
    }
   ],
   "source": [
    "# According to the instructure, the ratio should be 5:1:1\n",
    "# It is roughly the same as 5:1:1\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# Spliting the dataframe into train, val, and test with roughly 5:1:1\n",
    "train_val, test = train_test_split(cleaned_data, test_size=test_ratio, random_state=110)\n",
    "train, val = train_test_split(train_val, test_size=val_ratio/(train_ratio+val_ratio), random_state=110)\n",
    "\n",
    "# print the shapes of the resulting dataframes\n",
    "print(f\"Training set shape: {train.shape}\")\n",
    "print(f\"Validation set shape: {val.shape}\")\n",
    "print(f\"Testing set shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"two_year_recid\"\n",
    "sensitive_feature = \"race\"\n",
    "features = list(cleaned_data.columns)\n",
    "\n",
    "X_train = train.drop(label, axis=1)\n",
    "Y_train = train[label].to_numpy()\n",
    "\n",
    "X_val = val.drop(label, axis=1)\n",
    "Y_val = val[label].to_numpy()\n",
    "\n",
    "X_test = test.drop(label, axis=1)\n",
    "Y_test = test[label].to_numpy()\n",
    "\n",
    "race_train = train[sensitive_feature]\n",
    "race_val = val[sensitive_feature]\n",
    "race_test = test[sensitive_feature]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Functions defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration\n",
    "# Computes the calibration difference between Caucasians and African-Americans groups in the predicted outcomes.\n",
    "def calibrate_difference(sensitive_features, y_pred, y_true):\n",
    "    caucasians_index = np.where(sensitive_features == 1)[0]\n",
    "    aa_index = np.where(sensitive_features == 0)[0]\n",
    "    y_pred_caucasians = y_pred[caucasians_index]\n",
    "    y_true_caucasians = y_true[caucasians_index]\n",
    "    y_pred_aa = y_pred[aa_index]\n",
    "    y_true_aa = y_true[aa_index]\n",
    "    accuracy_caucasians = sum(y_pred_caucasians == y_true_caucasians) / len(y_true_caucasians)\n",
    "    accuracy_aa = sum(y_pred_aa == y_true_aa) / len(y_true_aa)\n",
    "    calib_diff = abs(accuracy_caucasians - accuracy_aa)\n",
    "    return calib_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_rule\n",
    "def p_rule(sensitive_features, y_pred):\n",
    "    caucasians_index = np.where(sensitive_features == 1)[0]\n",
    "    aa_index = np.where(sensitive_features == 0)[0]\n",
    "    caucasians_pred = np.where(y_pred[caucasians_index] == 1)\n",
    "    aa_pred = np.where(y_pred[aa_index] == 1)\n",
    "    caucasians_percent = caucasians_pred[0].shape[0]/caucasians_index.shape[0]\n",
    "    aa_percent = aa_pred[0].shape[0]/aa_index.shape[0]\n",
    "    ratio = min(caucasians_percent/aa_percent, aa_percent/caucasians_percent)\n",
    "    return ratio, caucasians_percent, aa_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use hinge loss function to compute the loss\n",
    "def hinge_loss(w, X, y, C):\n",
    "    y_hat = y * np.dot(X,w)\n",
    "    y_hat = np.maximum(np.zeros_like(y_hat), (1-y_hat)) # hinge function\n",
    "    \n",
    "    return C*sum(y_hat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Baseline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        4.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation set: 0.672514619883041\n",
      "Test accuracy: 0.6573\n"
     ]
    }
   ],
   "source": [
    "# Fit a logistic regression classifier\n",
    "lr_base = LogisticRegression(random_state=110)\n",
    "lr_base.fit(X_train, Y_train)\n",
    "\n",
    "# On validation set\n",
    "accuracy_lr_base_val = lr_base.score(X_val, Y_val)\n",
    "print(f\"Accuracy on the validation set: {accuracy_lr_base_val}\")\n",
    "\n",
    "# Testing \n",
    "accuracy_lr_base_test = lr_base.score(X_test, Y_test)\n",
    "print(f\"Test accuracy: {accuracy_lr_base_test:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        4.2 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation set: 0.6678362573099416\n",
      "Test accuracy: 0.6585\n"
     ]
    }
   ],
   "source": [
    "# Fit an SVM classifier\n",
    "svm_base = SVC(random_state=110)\n",
    "svm_base.fit(X_train, Y_train)\n",
    "\n",
    "# On validation\n",
    "accuracy_svm_base_val = svm_base.score(X_val, Y_val)\n",
    "print(f\"Accuracy on the validation set: {accuracy_svm_base_val}\")\n",
    "\n",
    "# Testing\n",
    "accuracy_svm_base_test = svm_base.score(X_test, Y_test)\n",
    "print(f\"Test accuracy: {accuracy_svm_base_test:.4f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        4.3 Summary of Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methods</th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Calibration(%)</th>\n",
       "      <th>p_rule</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>Val</td>\n",
       "      <td>67.251462</td>\n",
       "      <td>1.973728</td>\n",
       "      <td>0.426691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>Test</td>\n",
       "      <td>65.730994</td>\n",
       "      <td>0.393226</td>\n",
       "      <td>0.544211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Val</td>\n",
       "      <td>66.783626</td>\n",
       "      <td>2.596923</td>\n",
       "      <td>0.491003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Test</td>\n",
       "      <td>65.847953</td>\n",
       "      <td>2.654994</td>\n",
       "      <td>0.634721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Methods   Set  Accuracy (%)  Calibration(%)    p_rule\n",
       "0      LR   Val     67.251462        1.973728  0.426691\n",
       "1      LR  Test     65.730994        0.393226  0.544211\n",
       "2     SVM   Val     66.783626        2.596923  0.491003\n",
       "3     SVM  Test     65.847953        2.654994  0.634721"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_baseline = {\"Methods\": [\"LR\", \"LR\", \"SVM\", \"SVM\"], \n",
    "              \"Set\": [\"Val\", \"Test\", \"Val\", \"Test\"],\n",
    "              \"Accuracy (%)\": [accuracy_lr_base_val*100, accuracy_lr_base_test*100, accuracy_svm_base_val*100, accuracy_svm_base_test*100],\n",
    "              \"Calibration(%)\": [calibrate_difference(race_val, lr_base.predict(X_val), Y_val)*100,\n",
    "                                 calibrate_difference(race_test, lr_base.predict(X_test), Y_test)*100,\n",
    "                                 calibrate_difference(race_val, svm_base.predict(X_val), Y_val)*100,\n",
    "                                 calibrate_difference(race_test, svm_base.predict(X_test), Y_test)*100],\n",
    "              \"p_rule\": [p_rule(race_val, lr_base.predict(X_val))[0],\n",
    "                                 p_rule(race_test, lr_base.predict(X_test))[0],\n",
    "                                 p_rule(race_val, svm_base.predict(X_val))[0],\n",
    "                                 p_rule(race_test, svm_base.predict(X_test))[0]]}\n",
    "pd.DataFrame(summary_baseline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Optimization with Fairness Constraints (Paper A2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        5.1 CLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model, use from utils\n",
    "np.random.seed(100)\n",
    "w = ut.train_model(X_train,\n",
    "                   Y_train,\n",
    "                   x_control = {'race': race_train},\n",
    "                   loss_function = lf._logistic_loss,\n",
    "                   apply_fairness_constraints = 1,\n",
    "                   apply_accuracy_constraint = 0,\n",
    "                   sep_constraint = 0,\n",
    "                   sensitive_attrs = ['race'],\n",
    "                   sensitive_attrs_to_cov_thresh = {'race': 0},\n",
    "                   gamma = None)\n",
    "\n",
    "\n",
    "# Fit coefficients/weights into logistic regression in sklearn\n",
    "CLR = LogisticRegression()\n",
    "CLR.coef_= w.reshape((1,-1))\n",
    "CLR.intercept_ = 0\n",
    "CLR.classes_ = np.array([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation set: 0.48771929824561405\n",
      "Test accuracy: 0.4982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xu/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:402: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/xu/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:402: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# On validation set\n",
    "accuracy_CLR_val = CLR.score(X_val, Y_val)\n",
    "print(f\"Accuracy on the validation set: {accuracy_CLR_val}\")\n",
    "\n",
    "# Testing \n",
    "accuracy_CLR_test = CLR.score(X_test, Y_test)\n",
    "print(f\"Test accuracy: {accuracy_CLR_test:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        5.2 CSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running custom model\n"
     ]
    }
   ],
   "source": [
    "CSVM = csvm.SVM()\n",
    "w = CSVM.train_model(X_train, \n",
    "                     Y_train, \n",
    "                     x_control = {'race': race_train}, \n",
    "                     loss_function = hinge_loss, \n",
    "                     C =1, \n",
    "                     max_iter = -1, \n",
    "                     lamb = 1, \n",
    "                     epochs = 1000, \n",
    "                     lr = 0.1, \n",
    "                     apply_fairness_constraints = 1, \n",
    "                     sensitive_attrs = ['race'],\n",
    "                     sensitive_attrs_to_cov_thresh = {'race': 0},\n",
    "                     gamma = None)\n",
    "csvm_predict_y_val = np.sign(np.dot(X_val, w))\n",
    "csvm_predict_y_test = np.sign(np.dot(X_test, w))\n",
    "csvm_val_accuracy = sum(csvm_predict_y_val == Y_val)/len(Y_val)\n",
    "csvm_test_accuracy = sum(csvm_predict_y_test == Y_test)/len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Calibration (%)</th>\n",
       "      <th>p_rule</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C-SVM</td>\n",
       "      <td>Val</td>\n",
       "      <td>47.017544</td>\n",
       "      <td>8.93973</td>\n",
       "      <td>0.941057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C-SVM</td>\n",
       "      <td>Test</td>\n",
       "      <td>47.485380</td>\n",
       "      <td>5.43628</td>\n",
       "      <td>0.938462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier   Set  Accuracy (%)  Calibration (%)    p_rule\n",
       "0      C-SVM   Val     47.017544          8.93973  0.941057\n",
       "1      C-SVM  Test     47.485380          5.43628  0.938462"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_c_svm = {\"Classifier\": [\"C-SVM\", \"C-SVM\"],\n",
    "                \"Set\": [\"Val\", \"Test\"],\n",
    "                \"Accuracy (%)\": [csvm_val_accuracy*100, csvm_test_accuracy*100],\n",
    "                \"Calibration (%)\": [calibrate_difference(race_val, csvm_predict_y_val, Y_val) * 100, \n",
    "                                    calibrate_difference(race_test, csvm_predict_y_test, Y_test) * 100],\n",
    "                \"p_rule\": [p_rule(race_val, csvm_predict_y_val)[0],\n",
    "                           p_rule(race_test, csvm_predict_y_test)[0]]}\n",
    "pd.DataFrame(summary_c_svm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        5.3 Summary of A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xu/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:402: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/xu/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:402: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/xu/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:402: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/xu/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:402: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methods</th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Calibration(%)</th>\n",
       "      <th>p_rule</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLR</td>\n",
       "      <td>Val</td>\n",
       "      <td>48.771930</td>\n",
       "      <td>11.988510</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLR</td>\n",
       "      <td>Test</td>\n",
       "      <td>49.824561</td>\n",
       "      <td>8.791619</td>\n",
       "      <td>0.998936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CSVM</td>\n",
       "      <td>Val</td>\n",
       "      <td>47.017544</td>\n",
       "      <td>8.939730</td>\n",
       "      <td>0.941057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSVM</td>\n",
       "      <td>Test</td>\n",
       "      <td>47.485380</td>\n",
       "      <td>5.436280</td>\n",
       "      <td>0.938462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Methods   Set  Accuracy (%)  Calibration(%)    p_rule\n",
       "0     CLR   Val     48.771930       11.988510  1.000000\n",
       "1     CLR  Test     49.824561        8.791619  0.998936\n",
       "2    CSVM   Val     47.017544        8.939730  0.941057\n",
       "3    CSVM  Test     47.485380        5.436280  0.938462"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_A2 = {\"Methods\": [\"CLR\", \"CLR\", \"CSVM\", \"CSVM\"], \n",
    "              \"Set\": [\"Val\", \"Test\", \"Val\", \"Test\"],\n",
    "              \"Accuracy (%)\": [accuracy_CLR_val*100, accuracy_CLR_test*100, csvm_val_accuracy*100, csvm_test_accuracy*100],\n",
    "              \"Calibration(%)\": [calibrate_difference(race_val, CLR.predict(X_val), Y_val)*100,\n",
    "                                 calibrate_difference(race_test, CLR.predict(X_test), Y_test)*100,\n",
    "                                 calibrate_difference(race_val, csvm_predict_y_val, Y_val) * 100,\n",
    "                                 calibrate_difference(race_test, csvm_predict_y_test, Y_test) * 100],\n",
    "              \"p_rule\": [p_rule(race_val, CLR.predict(X_val))[0],\n",
    "                                 p_rule(race_test, CLR.predict(X_test))[0],\n",
    "                                 p_rule(race_val, csvm_predict_y_val)[0],\n",
    "                                 p_rule(race_test, csvm_predict_y_test)[0]]}\n",
    "\n",
    "pd.DataFrame(summary_A2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Local Massaging & Local Preferential Sampling (Paper A6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        6.1 Local Massaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df is the dataframe with all columns to be partitioned\n",
    "#e is the name of explainatory varaible\n",
    "def PARTITION(df, e):\n",
    "    groups = []\n",
    "    uniques = np.unique(df[e])\n",
    "    for u in uniques:\n",
    "        groups.append(df[df[e]==u])\n",
    "    return groups\n",
    "    \n",
    "#part is the dataframe with all columns with same value for the explainatory variable\n",
    "#si is the current sensitive parameter value\n",
    "def DELTA(df, part, si):\n",
    "    isRace = part['race']==si\n",
    "    Gi = sum(isRace)\n",
    "    n = len(df)\n",
    "    \n",
    "    num = sum(part[isRace]['two_year_recid']==1)/n\n",
    "    denom = len(part[isRace])/n\n",
    "    P = num/denom\n",
    "    \n",
    "    isNotRace = part['race']!=si\n",
    "    num = sum(part[isNotRace]['two_year_recid']==1)/n\n",
    "    denom = len(part[isNotRace])/n\n",
    "\n",
    "    P_star = 0.5*(P + num/denom) #explainable difference\n",
    "    return np.floor(Gi*abs(P-P_star)).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Local Massaging algorithm\n",
    "LM_labels = []\n",
    "for part in PARTITION(train, 'c_charge_degree'):\n",
    "    #train model\n",
    "    X_part = part.drop('two_year_recid', axis=1)\n",
    "    y_part = part['two_year_recid']\n",
    "    log_model = LogisticRegression(random_state=110)\n",
    "    model=log_model.fit(X_part, y_part)\n",
    "    \n",
    "    #predict labels from model\n",
    "    part1 = part[part['race']==1]\n",
    "    part1.reset_index(drop=True, inplace=True)\n",
    "    delta1 = DELTA(train, part, 1)\n",
    "    X_part1 = part1.drop('two_year_recid', axis=1)\n",
    "    y_part1 = part1['two_year_recid']\n",
    "    rank = pd.DataFrame(model.decision_function(X_part1), columns = ['rank'])\n",
    "    comb1 = pd.concat([part1, rank], axis=1)\n",
    "    \n",
    "    part0 = part[part['race']==0]\n",
    "    part0.reset_index(drop=True, inplace=True)\n",
    "    delta0 = DELTA(train, part, 0)\n",
    "    X_part0 = part0.drop('two_year_recid', axis=1)\n",
    "    y_part0 = part0['two_year_recid']\n",
    "    rank = pd.DataFrame(model.decision_function(X_part0), columns = ['rank'])\n",
    "    comb0 = pd.concat([part0, rank], axis=1)\n",
    "\n",
    "    #for C, relabel closest delta datapoints from C to AA\n",
    "    comb1 = comb1.sort_values(['rank'])\n",
    "    comb1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    t = sum(comb1['rank']>0)\n",
    "    l = len(comb1)\n",
    "    \n",
    "    fix1 = np.full(l-t, False)\n",
    "    relabel = np.full(delta1, True)\n",
    "    fix2 = np.full(t-delta1, False)\n",
    "    comb1.loc[np.concatenate([fix1, relabel, fix2]), 'two_year_recid'] = 0\n",
    "    LM_labels.append(comb1)\n",
    "    \n",
    "    #for AA, relabel closest delta datapoints from AA to C\n",
    "    comb0 = comb0.sort_values(['rank'])\n",
    "    comb0.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    t = sum(comb0['rank']<0)\n",
    "    l = len(comb0)\n",
    "    \n",
    "    fix1 = np.full(t-delta0, False)\n",
    "    relabel = np.full(delta0, True)\n",
    "    fix2 = np.full(l-t, False)\n",
    "    comb0.loc[np.concatenate([fix1, relabel, fix2]), 'two_year_recid'] = 1\n",
    "    LM_labels.append(comb0)\n",
    "    \n",
    "loc_mass = pd.concat(LM_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[\"sex\", \"race\", \"age_cat\", \"c_charge_degree\", \"v_score_text\", \"score_text\", \"priors_count\", \"length_of_stay\"]\n",
    "X_train_mass = loc_mass[features]\n",
    "Y_train_mass = loc_mass['two_year_recid'].reset_index(drop = True)\n",
    "log_model = LogisticRegression(random_state=110)\n",
    "LM_model = log_model.fit(X_train_mass, Y_train_mass)\n",
    "LM_acc_train = log_model.score(X_train_mass, Y_train_mass)\n",
    "LM_acc_test = LM_model.score(X_test, Y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        6.2 Local Preferential Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Local Preferential Sampling\n",
    "LPS_labels = []\n",
    "partition = PARTITION(train, 'c_charge_degree')\n",
    "for part in partition:\n",
    "    #train model\n",
    "    X_part = part.drop(\"two_year_recid\", axis=1)\n",
    "    y_part = part[\"two_year_recid\"]\n",
    "    log_model = LogisticRegression(random_state=110)\n",
    "    model = log_model.fit(X_part, y_part)\n",
    "    \n",
    "    #predict labels from model\n",
    "    part1 = part[part[\"race\"]==1]\n",
    "    part1.reset_index(drop=True, inplace=True)\n",
    "    delta1 = DELTA(train, part, 1)//2\n",
    "    X_part1 = part1.drop(\"two_year_recid\", axis=1)\n",
    "    y_part1 = part1[\"two_year_recid\"]\n",
    "    rank = pd.DataFrame(model.decision_function(X_part1), columns = ['rank'])\n",
    "    comb1 = pd.concat([part1, rank], axis=1)\n",
    "    \n",
    "    part0 = part[part[\"race\"]==0]\n",
    "    part0.reset_index(drop=True, inplace=True)\n",
    "    delta0 = DELTA(train, part, 0)//2\n",
    "    X_part0 = part0.drop(\"two_year_recid\", axis=1)\n",
    "    y_part0 = part0[\"two_year_recid\"]\n",
    "    rank = pd.DataFrame(model.decision_function(X_part0), columns = ['rank'])\n",
    "    comb0 = pd.concat([part0, rank], axis=1)\n",
    "\n",
    "    #for C, replace closest delta/2 data with duplicates from same number of AA \n",
    "    comb1 = comb1.sort_values([\"rank\"])\n",
    "    comb1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    t = sum(comb1[\"rank\"]>0)\n",
    "    l = len(comb1)\n",
    "    \n",
    "    keep1 = np.full(l-t, False)\n",
    "    replace = np.full(delta1, True)\n",
    "    keep2 = np.full(t-delta1, False)\n",
    "    toKeep = np.invert(np.concatenate([keep1, replace, keep2]))\n",
    "    dup1 = np.full(l-t-delta1, False)\n",
    "    dup2 = np.full(t, False)\n",
    "    toDup = np.concatenate([dup1, replace, dup2])\n",
    "    duplicates = comb1[toDup]\n",
    "    comb1 = comb1[toKeep]\n",
    "    comb1 = pd.concat([comb1,duplicates], axis=0)\n",
    "    LPS_labels.append(comb1)\n",
    "    \n",
    "    #for AA, replace closest delta/2 data with duplicates from same number of C \n",
    "    comb0 = comb0.sort_values(['rank'])\n",
    "    comb0.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    t = sum(comb0['rank']<0)\n",
    "    l = len(comb0)\n",
    "    \n",
    "    keep1 = np.full(t-delta0, False)\n",
    "    replace = np.full(delta0, True)\n",
    "    keep2 = np.full(l-t, False)\n",
    "    toKeep = np.invert(np.concatenate([keep1, replace, keep2]))\n",
    "    dup1 = np.full(t, False)\n",
    "    dup2 = np.full(l-t-delta0, False)\n",
    "    toDup = np.concatenate([dup1, replace, dup2])\n",
    "    duplicates = comb0[toDup]\n",
    "    comb0 = comb0[toKeep]\n",
    "    comb0 = pd.concat([comb0,duplicates], axis=0)\n",
    "    LPS_labels.append(comb0)\n",
    "\n",
    "loc_lps = pd.concat(LPS_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[\"sex\", \"race\", \"age_cat\", \"c_charge_degree\", \"v_score_text\", \"score_text\", \"priors_count\", \"length_of_stay\"]\n",
    "X_train_lps = loc_lps[features]\n",
    "Y_train_lps = loc_lps['two_year_recid'].reset_index(drop = True)\n",
    "log_model = LogisticRegression(random_state=110)\n",
    "LPS_model = log_model.fit(X_train_lps, Y_train_lps)\n",
    "LPS_acc_train = log_model.score(X_train_lps, Y_train_lps)\n",
    "LPS_acc_test = LPS_model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methods</th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Calibration(%)</th>\n",
       "      <th>p_rule</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Local Massaging (LR)</td>\n",
       "      <td>Train</td>\n",
       "      <td>69.942341</td>\n",
       "      <td>0.849556</td>\n",
       "      <td>0.992513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Local Massaging (LR)</td>\n",
       "      <td>Test</td>\n",
       "      <td>64.561404</td>\n",
       "      <td>1.334673</td>\n",
       "      <td>0.337680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Local Preferential Sampling (LR)</td>\n",
       "      <td>Train</td>\n",
       "      <td>69.089997</td>\n",
       "      <td>0.354507</td>\n",
       "      <td>0.973000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Local Preferential Sampling (LR)</td>\n",
       "      <td>Test</td>\n",
       "      <td>65.614035</td>\n",
       "      <td>0.094719</td>\n",
       "      <td>0.571877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Methods    Set  Accuracy (%)  Calibration(%)  \\\n",
       "0              Local Massaging (LR)  Train     69.942341        0.849556   \n",
       "1              Local Massaging (LR)   Test     64.561404        1.334673   \n",
       "2  Local Preferential Sampling (LR)  Train     69.089997        0.354507   \n",
       "3  Local Preferential Sampling (LR)   Test     65.614035        0.094719   \n",
       "\n",
       "     p_rule  \n",
       "0  0.992513  \n",
       "1  0.337680  \n",
       "2  0.973000  \n",
       "3  0.571877  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_A6 = {\"Methods\": [\"Local Massaging (LR)\", \"Local Massaging (LR)\", \"Local Preferential Sampling (LR)\", \"Local Preferential Sampling (LR)\"], \n",
    "              \"Set\": [\"Train\", \"Test\", \"Train\", \"Test\"],\n",
    "              \"Accuracy (%)\": [LM_acc_train*100, LM_acc_test*100, LPS_acc_train*100, LPS_acc_test*100],\n",
    "              \"Calibration(%)\": [calibrate_difference(race_train, LM_model.predict(X_train_mass), Y_train_mass)*100,\n",
    "                                 calibrate_difference(race_test, LM_model.predict(X_test), Y_test)*100,\n",
    "                                 calibrate_difference(race_train, LPS_model.predict(X_train_lps), Y_train_lps)*100,\n",
    "                                 calibrate_difference(race_test, LPS_model.predict(X_test), Y_test)*100],\n",
    "              \"p_rule\": [p_rule(race_train, LM_model.predict(X_train_mass))[0],\n",
    "                                 p_rule(race_test, LM_model.predict(X_test))[0],\n",
    "                                 p_rule(race_train, LPS_model.predict(X_train_lps))[0],\n",
    "                                 p_rule(race_test, LPS_model.predict(X_test))[0]]}\n",
    "pd.DataFrame(summary_A6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Summary Evaluation of Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xu/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:402: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/xu/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:402: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methods</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Calibration(%)</th>\n",
       "      <th>p_rule</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline LR</td>\n",
       "      <td>65.730994</td>\n",
       "      <td>0.393226</td>\n",
       "      <td>0.544211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline SVM</td>\n",
       "      <td>65.847953</td>\n",
       "      <td>2.654994</td>\n",
       "      <td>0.634721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLR</td>\n",
       "      <td>49.824561</td>\n",
       "      <td>8.791619</td>\n",
       "      <td>0.998936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSVM</td>\n",
       "      <td>47.485380</td>\n",
       "      <td>5.436280</td>\n",
       "      <td>0.938462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Local Massaging (LR)</td>\n",
       "      <td>64.561404</td>\n",
       "      <td>1.334673</td>\n",
       "      <td>0.337680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Local Preferential Sampling (LR)</td>\n",
       "      <td>65.614035</td>\n",
       "      <td>0.094719</td>\n",
       "      <td>0.571877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Methods  Accuracy (%)  Calibration(%)    p_rule\n",
       "0                       Baseline LR     65.730994        0.393226  0.544211\n",
       "1                      Baseline SVM     65.847953        2.654994  0.634721\n",
       "2                               CLR     49.824561        8.791619  0.998936\n",
       "3                              CSVM     47.485380        5.436280  0.938462\n",
       "4              Local Massaging (LR)     64.561404        1.334673  0.337680\n",
       "5  Local Preferential Sampling (LR)     65.614035        0.094719  0.571877"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = {\"Methods\": [\"Baseline LR\", \"Baseline SVM\", \n",
    "                       \"CLR\", \"CSVM\",\n",
    "                       \"Local Massaging (LR)\", \"Local Preferential Sampling (LR)\"], \n",
    "              \"Accuracy (%)\": [accuracy_lr_base_test*100, accuracy_svm_base_test*100, \n",
    "                               accuracy_CLR_test*100, csvm_test_accuracy*100,\n",
    "                               LM_acc_test*100, LPS_acc_test*100],\n",
    "              \"Calibration(%)\": [calibrate_difference(race_test, lr_base.predict(X_test), Y_test)*100,\n",
    "                                 calibrate_difference(race_test, svm_base.predict(X_test), Y_test)*100,\n",
    "                                 calibrate_difference(race_test, CLR.predict(X_test), Y_test)*100,\n",
    "                                 calibrate_difference(race_test, csvm_predict_y_test, Y_test) * 100,\n",
    "                                 calibrate_difference(race_test, LM_model.predict(X_test), Y_test)*100,\n",
    "                                 calibrate_difference(race_test, LPS_model.predict(X_test), Y_test)*100],\n",
    "              \"p_rule\": [p_rule(race_test, lr_base.predict(X_test))[0],\n",
    "                                 p_rule(race_test, svm_base.predict(X_test))[0],\n",
    "                                 p_rule(race_test, CLR.predict(X_test))[0],\n",
    "                                 p_rule(race_test, csvm_predict_y_test)[0],\n",
    "                                 p_rule(race_test, LM_model.predict(X_test))[0],\n",
    "                                 p_rule(race_test, LPS_model.predict(X_test))[0]]}\n",
    "pd.DataFrame(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
